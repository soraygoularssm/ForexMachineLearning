{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "forex_cnn_keras.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "TgidDS3QsNhK",
        "KRm5t_3pUyby",
        "H5Tz7RqnvGVp",
        "z8ZjHK8IdsfQ"
      ],
      "mount_file_id": "1NMbCWOzG6cYSK2B5y8sOn_M3brU-Xq6i",
      "authorship_tag": "ABX9TyNQv7EtHNHuF+O49qdMwqZ+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgidDS3QsNhK"
      },
      "source": [
        "#**install and imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUXjQADx4ptE"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAA5RV0p-Usu"
      },
      "source": [
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAdez97m7JZH"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QV2yjR0Dl8U"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, MaxPooling1D , Conv1D , Dropout , Activation , Embedding , Input , Lambda , Conv2D , MaxPooling2D , Flatten\n",
        "# from keras.optimizers import SGD\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import keras\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import BatchNormalization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRm5t_3pUyby"
      },
      "source": [
        "#**Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h060Wf3I4nX7"
      },
      "source": [
        "# loaded_arr = np.loadtxt('/content/full_data.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsVagcCf40MQ"
      },
      "source": [
        "# n = 5\n",
        "# load_original_arr = loaded_arr.reshape(\n",
        "#     loaded_arr.shape[0], loaded_arr.shape[1] // n, n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47NxiFJXu6TF"
      },
      "source": [
        "# load_original_arr.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tx_iOmTKeloS"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/programming/full_data.csv')\n",
        "# df['mid']\n",
        "# df.loc[:,'rsi1':]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQp6WIi3IKRR"
      },
      "source": [
        "df.loc[:,'rsi1':] = df.loc[:,'rsi1':]\n",
        "df = df.iloc[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGkjiXUrwwM4"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5Tz7RqnvGVp"
      },
      "source": [
        "#**split the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Y-414xQDlEL"
      },
      "source": [
        "# scaler = MinMaxScaler()\n",
        "# scaled = scaler.fit_transform(load_original_arr.reshape(-1,1))\n",
        "# scaled = scaled.reshape(load_original_arr.shape)\n",
        "# scaled = load_original_arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHsNXwwxdb11"
      },
      "source": [
        "g = df.groupby('Action')\n",
        "df = g.apply(lambda x: x.sample(g.size().min()).reset_index(drop=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TERhxeUYvIoH"
      },
      "source": [
        "X = df.loc[:,'rsi1':]\n",
        "# X = X[sorted_columns]\n",
        "X = X.values\n",
        "y = df.loc[:,'Action'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gadc_OFZwYpB"
      },
      "source": [
        "X_train , X_validation , y_train , y_validation = train_test_split(X,y,test_size = 0.2 , shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woypuOWPkmyh"
      },
      "source": [
        "mm_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X_train = mm_scaler.fit_transform(X_train)\n",
        "X_validation = mm_scaler.fit_transform(X_validation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHxjFf99xt-t"
      },
      "source": [
        "y_train = [y for y in y_train]\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "y_validation = [y for y in y_validation]\n",
        "y_validation = np.array(y_validation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIjh49s1n5Lo"
      },
      "source": [
        "y_train = to_categorical(y_train, 3)\n",
        "y_validation = to_categorical(y_validation, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD1HpPou3Y96"
      },
      "source": [
        "X_validation.shape , y_validation.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8ZjHK8IdsfQ"
      },
      "source": [
        "#**Visualizing Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRoZQ680lyb1"
      },
      "source": [
        "from PIL import Image as im"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfdqx0W9lVPx"
      },
      "source": [
        "for i in range(30):\n",
        "  d = np.reshape(X_train, (X_train.shape[0] , 15, 15))[i]\n",
        "  plt.imshow(d , interpolation='nearest')\n",
        "  plt.show()\n",
        "  print(y[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pmy5mA9oEf5h"
      },
      "source": [
        "#**train CNNs model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btNLGGh-yf1G"
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0] , 15 , 15 , 1)\n",
        "X_validation = X_validation.reshape(X_validation.shape[0] , 15 , 15 , 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eiZVayavreB"
      },
      "source": [
        "def define_model():\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "# convolutional layer\n",
        "  model.add(Conv2D(50, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', input_shape=(32, 32, 3)))\n",
        "\n",
        "# convolutional layer\n",
        "  model.add(Conv2D(75, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
        "  model.add(MaxPooling1D(pool_size=(2,2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(125, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
        "  model.add(MaxPooling1D(pool_size=(2,2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "# flatten output of conv\n",
        "  model.add(Flatten())\n",
        "\n",
        "# hidden layer\n",
        "  model.add(Dense(500, activation='relu'))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Dense(250, activation='relu'))\n",
        "  model.add(Dropout(0.3))\n",
        "# output layer\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# compiling the sequential model\n",
        "  model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfK7JqAphf7Z"
      },
      "source": [
        "model = define_model()\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_validation, y_validation), verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEgMhe9JzoGV"
      },
      "source": [
        "scores = model.evaluate(X_validation, y_validation, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7l_FKgPrIZ4w"
      },
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6pwmCY5GVr-"
      },
      "source": [
        "prediction = np.argmax(model.predict(X_validation), axis=-1)\n",
        "print(prediction.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0za5DS9PH_mt"
      },
      "source": [
        "scaler.inverse_transform(prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHt7z0Y5xKJs"
      },
      "source": [
        "model.save_weights(\"model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WwXfCpE2swJ"
      },
      "source": [
        "#**train multiple models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XKQ70gX2veb"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_LUuEM52wq_"
      },
      "source": [
        "models = []\n",
        "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
        "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
        "models.append(('KNN', KNeighborsClassifier()))\n",
        "models.append(('CART', DecisionTreeClassifier()))\n",
        "models.append(('NB', GaussianNB()))\n",
        "models.append(('SVM', SVC(gamma='auto')))\n",
        "# evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "for name, model in models:\n",
        "\tkfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
        "\tcv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
        "\tresults.append(cv_results)\n",
        "\tnames.append(name)\n",
        "\tprint('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}